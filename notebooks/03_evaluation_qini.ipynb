{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Phase 3: Model Evaluation — Qini Curves & Calibration Analysis\n",
                "\n",
                "## Uplift Modeling Project — \"The Persuadable Hunter\"\n",
                "\n",
                "This notebook covers:\n",
                "1. **Qini Curve** — The standard metric for uplift model evaluation\n",
                "2. **Random Baseline** — How much better are we than random targeting?\n",
                "3. **AUUC Calculation** — Area Under the Uplift Curve\n",
                "4. **Calibration Analysis** — Investigating the Decile 9 anomaly\n",
                "5. **Model Interpretation** — What the curves tell us about our model\n",
                "\n",
                "---\n",
                "\n",
                "### Key Insight from Phase 2\n",
                "\n",
                "Gemini (Senior Mentor) identified an interesting pattern in the Decile Analysis:\n",
                "\n",
                "| Decile | Control % | Treatment % | Observed Lift |\n",
                "|--------|-----------|-------------|---------------|\n",
                "| 8 | 0.32% | 1.53% | **+1.22pp** (best!) |\n",
                "| 9 | **1.29%** | 1.53% | +0.24pp (anomaly) |\n",
                "| 10 | 0.93% | 1.88% | +0.95pp |\n",
                "\n",
                "**Decile 9 has the highest Control conversion rate** → These are \"Sure Things\" who buy regardless of email. The model confused high baseline conversion with high persuadability.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from scipy import stats\n",
                "from scipy.integrate import trapezoid  # For AUUC calculation (np.trapz deprecated)\n",
                "import joblib\n",
                "\n",
                "# Set style\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "plt.rcParams['font.size'] = 11\n",
                "\n",
                "# Suppress warnings\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "RANDOM_STATE = 42\n",
                "np.random.seed(RANDOM_STATE)\n",
                "\n",
                "print(\"Libraries loaded successfully!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load test results with uplift scores from Phase 2\n",
                "results_df = pd.read_csv('../data/test_results_with_uplift.csv')\n",
                "\n",
                "print(f\"Test Results Shape: {results_df.shape[0]:,} rows × {results_df.shape[1]} columns\")\n",
                "print(f\"\\nColumns: {list(results_df.columns)}\")\n",
                "print(f\"\\nUplift Score Stats:\")\n",
                "print(results_df['uplift_score'].describe())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract key columns\n",
                "y_true = results_df['y_true'].values          # Actual conversion (0/1)\n",
                "treatment = results_df['treatment'].values    # Treatment assignment (0/1)\n",
                "uplift_scores = results_df['uplift_score'].values  # Predicted uplift\n",
                "\n",
                "print(f\"Test set summary:\")\n",
                "print(f\"  Total customers: {len(y_true):,}\")\n",
                "print(f\"  Treated: {treatment.sum():,} ({treatment.mean()*100:.1f}%)\")\n",
                "print(f\"  Control: {(1-treatment).sum():,} ({(1-treatment.mean())*100:.1f}%)\")\n",
                "print(f\"  Conversions: {y_true.sum():,} ({y_true.mean()*100:.2f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 2. Understanding the Qini Curve\n",
                "\n",
                "### What is a Qini Curve?\n",
                "\n",
                "The Qini curve answers: **\"If I target the top X% of customers by uplift score, how many *incremental* conversions do I get?\"**\n",
                "\n",
                "**Key insight**: We can only measure incremental conversions on **treated vs. control** groups, not on individuals.\n",
                "\n",
                "### The Algorithm\n",
                "\n",
                "1. Rank all customers by uplift score (highest first)\n",
                "2. For each % of population targeted:\n",
                "   - Count conversions in the **treated** subset\n",
                "   - Count conversions in the **control** subset (scaled to same size)\n",
                "   - Incremental = Treated conversions - Scaled control conversions\n",
                "3. Plot cumulative incremental conversions\n",
                "\n",
                "### Interpretation\n",
                "\n",
                "- **Good model**: Curve rises steeply, then flattens (captured persuadables early)\n",
                "- **Random model**: Diagonal line\n",
                "- **Bad model**: Below the diagonal"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_qini_curve(y_true, treatment, uplift_scores, n_bins=100):\n",
                "    \"\"\"\n",
                "    Calculate Qini curve data.\n",
                "    \n",
                "    Returns:\n",
                "        percentages: % of population targeted\n",
                "        qini_values: Cumulative incremental conversions\n",
                "        random_values: Random baseline values\n",
                "    \n",
                "    BUGFIX (Codex review): Ensure endpoint pct=1.0 is always included.\n",
                "    \"\"\"\n",
                "    # Sort by uplift score (descending)\n",
                "    sorted_idx = np.argsort(uplift_scores)[::-1]\n",
                "    y_sorted = y_true[sorted_idx]\n",
                "    t_sorted = treatment[sorted_idx]\n",
                "    \n",
                "    n = len(y_true)\n",
                "    n_treated = treatment.sum()\n",
                "    n_control = n - n_treated\n",
                "    \n",
                "    # Calculate at each point\n",
                "    percentages = []\n",
                "    qini_values = []\n",
                "    random_values = []\n",
                "    \n",
                "    # Total conversions for random baseline endpoint\n",
                "    total_treated_conversions = (y_true * treatment).sum()\n",
                "    total_control_conversions = (y_true * (1 - treatment)).sum()\n",
                "    \n",
                "    # Pre-calculate final qini for random baseline\n",
                "    scaled_control_total = total_control_conversions * (n_treated / n_control)\n",
                "    final_qini = total_treated_conversions - scaled_control_total\n",
                "    \n",
                "    step = max(1, n // n_bins)\n",
                "    \n",
                "    for i in range(1, n + 1, step):\n",
                "        pct = i / n\n",
                "        \n",
                "        # Subset up to position i\n",
                "        y_subset = y_sorted[:i]\n",
                "        t_subset = t_sorted[:i]\n",
                "        \n",
                "        # Count conversions in treatment and control\n",
                "        n_t_subset = t_subset.sum()\n",
                "        n_c_subset = i - n_t_subset\n",
                "        \n",
                "        conversions_t = (y_subset * t_subset).sum()\n",
                "        conversions_c = (y_subset * (1 - t_subset)).sum()\n",
                "        \n",
                "        # Scale control to match treatment size\n",
                "        if n_c_subset > 0 and n_t_subset > 0:\n",
                "            scaled_control = conversions_c * (n_t_subset / n_c_subset)\n",
                "            qini = conversions_t - scaled_control\n",
                "        else:\n",
                "            qini = 0\n",
                "        \n",
                "        # Random baseline: linear from 0 to final qini\n",
                "        random_qini = pct * final_qini\n",
                "        \n",
                "        percentages.append(pct)\n",
                "        qini_values.append(qini)\n",
                "        random_values.append(random_qini)\n",
                "    \n",
                "    # BUGFIX: Ensure we include the start point (0, 0)\n",
                "    if percentages[0] != 0:\n",
                "        percentages.insert(0, 0)\n",
                "        qini_values.insert(0, 0)\n",
                "        random_values.insert(0, 0)\n",
                "    \n",
                "    # BUGFIX (Codex): Ensure we include the endpoint (1.0, final_qini)\n",
                "    if percentages[-1] != 1.0:\n",
                "        # Calculate final point at 100% population\n",
                "        n_t_full = t_sorted.sum()\n",
                "        n_c_full = n - n_t_full\n",
                "        conv_t_full = (y_sorted * t_sorted).sum()\n",
                "        conv_c_full = (y_sorted * (1 - t_sorted)).sum()\n",
                "        \n",
                "        if n_c_full > 0 and n_t_full > 0:\n",
                "            scaled_control_full = conv_c_full * (n_t_full / n_c_full)\n",
                "            qini_full = conv_t_full - scaled_control_full\n",
                "        else:\n",
                "            qini_full = final_qini\n",
                "        \n",
                "        percentages.append(1.0)\n",
                "        qini_values.append(qini_full)\n",
                "        random_values.append(final_qini)\n",
                "    \n",
                "    return np.array(percentages), np.array(qini_values), np.array(random_values)\n",
                "\n",
                "print(\"Qini curve function defined (with endpoint bugfix)!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate Qini curve\n",
                "percentages, qini_values, random_values = calculate_qini_curve(\n",
                "    y_true, treatment, uplift_scores, n_bins=100\n",
                ")\n",
                "\n",
                "print(f\"Qini curve calculated with {len(percentages)} points\")\n",
                "print(f\"Endpoints: pct[0]={percentages[0]:.2f}, pct[-1]={percentages[-1]:.2f}\")\n",
                "print(f\"\\nFinal Qini value (100% targeted): {qini_values[-1]:.2f} incremental conversions\")\n",
                "print(f\"Random baseline endpoint: {random_values[-1]:.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 3. Plotting the Qini Curve with Random Baseline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot Qini Curve\n",
                "fig, ax = plt.subplots(figsize=(12, 8))\n",
                "\n",
                "# Model curve\n",
                "ax.plot(percentages * 100, qini_values, 'b-', linewidth=2.5, label='T-Learner Model')\n",
                "\n",
                "# Random baseline (CLEARLY MARKED as requested by Gemini)\n",
                "ax.plot(percentages * 100, random_values, 'r--', linewidth=2, label='Random Targeting (Baseline)')\n",
                "\n",
                "# Fill the area between (model gain)\n",
                "ax.fill_between(percentages * 100, random_values, qini_values, \n",
                "                alpha=0.3, color='green', label='Model Gain over Random')\n",
                "\n",
                "ax.set_xlabel('% of Population Targeted', fontsize=14)\n",
                "ax.set_ylabel('Cumulative Incremental Conversions', fontsize=14)\n",
                "ax.set_title('Qini Curve: T-Learner Uplift Model Evaluation', fontsize=16, fontweight='bold')\n",
                "ax.legend(loc='upper left', fontsize=12)\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "# Add annotations\n",
                "ax.axhline(y=0, color='gray', linestyle='-', linewidth=0.5)\n",
                "\n",
                "# Mark key points\n",
                "for pct in [0.1, 0.3, 0.5]:\n",
                "    idx = np.argmin(np.abs(percentages - pct))\n",
                "    ax.scatter([percentages[idx]*100], [qini_values[idx]], color='blue', s=100, zorder=5)\n",
                "    gain_over_random = qini_values[idx] - random_values[idx]\n",
                "    ax.annotate(f'{pct*100:.0f}%: +{gain_over_random:.1f} vs random', \n",
                "                xy=(percentages[idx]*100, qini_values[idx]),\n",
                "                xytext=(percentages[idx]*100 + 5, qini_values[idx] + 2),\n",
                "                fontsize=10, fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/qini_curve.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 4. AUUC Calculation (Area Under Uplift Curve)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_auuc(percentages, qini_values, random_values):\n",
                "    \"\"\"\n",
                "    Calculate Area Under the Uplift Curve.\n",
                "    \n",
                "    Returns:\n",
                "        auuc: Total area under model curve\n",
                "        auuc_random: Area under random baseline\n",
                "        auuc_gain: Gain over random (the metric we care about)\n",
                "        normalized_auuc: AUUC normalized by random (>1 = better than random)\n",
                "    \"\"\"\n",
                "    # Use trapezoidal rule for integration (scipy.integrate.trapezoid)\n",
                "    auuc = trapezoid(qini_values, percentages)\n",
                "    auuc_random = trapezoid(random_values, percentages)\n",
                "    auuc_gain = auuc - auuc_random\n",
                "    \n",
                "    # Normalized: how much better than random?\n",
                "    if auuc_random != 0:\n",
                "        normalized_auuc = auuc / auuc_random\n",
                "    else:\n",
                "        normalized_auuc = float('inf') if auuc > 0 else 0\n",
                "    \n",
                "    return auuc, auuc_random, auuc_gain, normalized_auuc\n",
                "\n",
                "auuc, auuc_random, auuc_gain, normalized_auuc = calculate_auuc(\n",
                "    percentages, qini_values, random_values\n",
                ")\n",
                "\n",
                "print(\"AUUC (Area Under Uplift Curve) Analysis\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"Model AUUC:      {auuc:.4f}\")\n",
                "print(f\"Random AUUC:     {auuc_random:.4f}\")\n",
                "print(f\"AUUC Gain:       {auuc_gain:.4f}\")\n",
                "print(f\"Normalized AUUC: {normalized_auuc:.2f}x (vs random baseline)\")\n",
                "print(f\"\\nInterpretation: Model is {(normalized_auuc-1)*100:.1f}% better than random targeting\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 5. Cumulative Uplift Curve (Alternative Visualization)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_cumulative_uplift_curve(y_true, treatment, uplift_scores, n_bins=10):\n",
                "    \"\"\"\n",
                "    Calculate observed uplift at each decile.\n",
                "    This is what we'll use to check the Decile 9 anomaly.\n",
                "    \"\"\"\n",
                "    # Create deciles\n",
                "    df = pd.DataFrame({\n",
                "        'y_true': y_true,\n",
                "        'treatment': treatment,\n",
                "        'uplift_score': uplift_scores\n",
                "    })\n",
                "    \n",
                "    # Assign deciles (1-10, where 10 = highest uplift)\n",
                "    df['decile'] = pd.qcut(df['uplift_score'], q=n_bins, labels=False, duplicates='drop') + 1\n",
                "    \n",
                "    # Calculate metrics per decile\n",
                "    decile_metrics = []\n",
                "    \n",
                "    for decile in sorted(df['decile'].unique()):\n",
                "        subset = df[df['decile'] == decile]\n",
                "        \n",
                "        treated = subset[subset['treatment'] == 1]\n",
                "        control = subset[subset['treatment'] == 0]\n",
                "        \n",
                "        if len(treated) > 0 and len(control) > 0:\n",
                "            treated_rate = treated['y_true'].mean()\n",
                "            control_rate = control['y_true'].mean()\n",
                "            observed_uplift = treated_rate - control_rate\n",
                "            predicted_uplift = subset['uplift_score'].mean()\n",
                "        else:\n",
                "            treated_rate = control_rate = observed_uplift = predicted_uplift = 0\n",
                "        \n",
                "        decile_metrics.append({\n",
                "            'decile': decile,\n",
                "            'n_customers': len(subset),\n",
                "            'n_treated': len(treated),\n",
                "            'n_control': len(control),\n",
                "            'treated_rate': treated_rate,\n",
                "            'control_rate': control_rate,\n",
                "            'observed_uplift': observed_uplift,\n",
                "            'predicted_uplift': predicted_uplift\n",
                "        })\n",
                "    \n",
                "    return pd.DataFrame(decile_metrics)\n",
                "\n",
                "decile_df = calculate_cumulative_uplift_curve(y_true, treatment, uplift_scores, n_bins=10)\n",
                "print(\"Decile Analysis:\")\n",
                "print(\"=\" * 90)\n",
                "decile_df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 6. Calibration Analysis: The Decile 9 Anomaly\n",
                "\n",
                "Gemini identified that Decile 9 has:\n",
                "- **Highest control rate** (Sure Things who buy anyway)\n",
                "- **Low observed lift** (little incremental value from email)\n",
                "\n",
                "This is a calibration issue: the model confuses \"high baseline conversion\" with \"high persuadability\"."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calibration Plot: Predicted vs Observed Uplift by Decile\n",
                "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
                "\n",
                "# Left: Predicted vs Observed Uplift\n",
                "ax = axes[0]\n",
                "x = decile_df['decile']\n",
                "ax.bar(x - 0.2, decile_df['predicted_uplift'] * 100, width=0.4, \n",
                "       label='Predicted Uplift', color='#3498db', alpha=0.8)\n",
                "ax.bar(x + 0.2, decile_df['observed_uplift'] * 100, width=0.4, \n",
                "       label='Observed Uplift', color='#2ecc71', alpha=0.8)\n",
                "ax.axhline(y=0, color='gray', linestyle='-', linewidth=0.5)\n",
                "ax.set_xlabel('Uplift Decile (1=Lowest, 10=Highest)', fontsize=12)\n",
                "ax.set_ylabel('Uplift (percentage points)', fontsize=12)\n",
                "ax.set_title('Model Calibration: Predicted vs Observed Uplift', fontsize=14, fontweight='bold')\n",
                "ax.legend(fontsize=11)\n",
                "ax.set_xticks(x)\n",
                "\n",
                "# Highlight Decile 9 anomaly\n",
                "decile_9 = decile_df[decile_df['decile'] == 9].iloc[0]\n",
                "ax.annotate('Decile 9 Anomaly:\\nHigh predicted,\\nlow observed uplift', \n",
                "            xy=(9, decile_9['observed_uplift']*100),\n",
                "            xytext=(7, decile_9['predicted_uplift']*100 + 0.5),\n",
                "            arrowprops=dict(arrowstyle='->', color='red', lw=2),\n",
                "            fontsize=10, color='red', fontweight='bold')\n",
                "\n",
                "# Right: Control Rate by Decile (The Root Cause)\n",
                "ax = axes[1]\n",
                "colors = ['#e74c3c' if d == 9 else '#3498db' for d in decile_df['decile']]\n",
                "bars = ax.bar(decile_df['decile'], decile_df['control_rate'] * 100, color=colors, alpha=0.8)\n",
                "ax.set_xlabel('Uplift Decile (1=Lowest, 10=Highest)', fontsize=12)\n",
                "ax.set_ylabel('Control Conversion Rate (%)', fontsize=12)\n",
                "ax.set_title('Root Cause: Control Rate by Decile', fontsize=14, fontweight='bold')\n",
                "ax.set_xticks(decile_df['decile'])\n",
                "\n",
                "# Highlight Decile 9\n",
                "ax.annotate('Decile 9 has HIGHEST\\ncontrol rate = \"Sure Things\"', \n",
                "            xy=(9, decile_9['control_rate']*100),\n",
                "            xytext=(6.5, decile_9['control_rate']*100 + 0.2),\n",
                "            arrowprops=dict(arrowstyle='->', color='red', lw=2),\n",
                "            fontsize=10, color='red', fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/calibration_analysis.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cumulative Uplift Curve by Decile (to check for Decile 9 dip)\n",
                "fig, ax = plt.subplots(figsize=(12, 7))\n",
                "\n",
                "# Calculate cumulative observed uplift (from Decile 10 down to 1)\n",
                "decile_df_sorted = decile_df.sort_values('decile', ascending=False)\n",
                "decile_df_sorted['cumulative_treated_conversions'] = (\n",
                "    decile_df_sorted['treated_rate'] * decile_df_sorted['n_treated']\n",
                ").cumsum()\n",
                "decile_df_sorted['cumulative_control_conversions'] = (\n",
                "    decile_df_sorted['control_rate'] * decile_df_sorted['n_control']\n",
                ").cumsum()\n",
                "decile_df_sorted['cumulative_n_treated'] = decile_df_sorted['n_treated'].cumsum()\n",
                "decile_df_sorted['cumulative_n_control'] = decile_df_sorted['n_control'].cumsum()\n",
                "\n",
                "# Scale control to treatment size\n",
                "decile_df_sorted['scaled_control'] = (\n",
                "    decile_df_sorted['cumulative_control_conversions'] * \n",
                "    decile_df_sorted['cumulative_n_treated'] / \n",
                "    decile_df_sorted['cumulative_n_control'].replace(0, 1)\n",
                ")\n",
                "decile_df_sorted['cumulative_incremental'] = (\n",
                "    decile_df_sorted['cumulative_treated_conversions'] - \n",
                "    decile_df_sorted['scaled_control']\n",
                ")\n",
                "\n",
                "# Percentage of population from high to low uplift\n",
                "decile_df_sorted['cum_pct'] = decile_df_sorted['n_customers'].cumsum() / decile_df_sorted['n_customers'].sum()\n",
                "\n",
                "# Plot\n",
                "ax.plot(decile_df_sorted['cum_pct'] * 100, decile_df_sorted['cumulative_incremental'], \n",
                "        'b-o', linewidth=2, markersize=8, label='Model')\n",
                "\n",
                "# Random baseline\n",
                "max_incr = decile_df_sorted['cumulative_incremental'].iloc[-1]\n",
                "ax.plot([0, 100], [0, max_incr], 'r--', linewidth=2, label='Random Baseline')\n",
                "\n",
                "# Mark each decile\n",
                "for _, row in decile_df_sorted.iterrows():\n",
                "    d = int(row['decile'])\n",
                "    color = 'red' if d == 9 else 'blue'\n",
                "    fontweight = 'bold' if d == 9 else 'normal'\n",
                "    ax.annotate(f'D{d}', xy=(row['cum_pct']*100, row['cumulative_incremental']),\n",
                "                xytext=(row['cum_pct']*100 + 2, row['cumulative_incremental'] + 0.5),\n",
                "                fontsize=9, color=color, fontweight=fontweight)\n",
                "\n",
                "ax.set_xlabel('% of Population Targeted (High to Low Uplift)', fontsize=12)\n",
                "ax.set_ylabel('Cumulative Incremental Conversions', fontsize=12)\n",
                "ax.set_title('Cumulative Uplift by Decile — Checking for Decile 9 Dip', fontsize=14, fontweight='bold')\n",
                "ax.legend(fontsize=11)\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/cumulative_uplift_by_decile.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Marginal uplift by decile (to see if Decile 9 dips)\n",
                "fig, ax = plt.subplots(figsize=(12, 6))\n",
                "\n",
                "colors = ['#e74c3c' if d == 9 else ('#27ae60' if u > 0 else '#95a5a6') \n",
                "          for d, u in zip(decile_df['decile'], decile_df['observed_uplift'])]\n",
                "\n",
                "bars = ax.bar(decile_df['decile'], decile_df['observed_uplift'] * 100, color=colors, alpha=0.8, edgecolor='white')\n",
                "ax.axhline(y=0, color='gray', linestyle='-', linewidth=1)\n",
                "\n",
                "# Add value labels\n",
                "for bar, (_, row) in zip(bars, decile_df.iterrows()):\n",
                "    height = bar.get_height()\n",
                "    label_y = height + 0.05 if height >= 0 else height - 0.15\n",
                "    ax.text(bar.get_x() + bar.get_width()/2, label_y, f'{height:.2f}pp',\n",
                "            ha='center', va='bottom' if height >= 0 else 'top', fontsize=10, fontweight='bold')\n",
                "\n",
                "ax.set_xlabel('Uplift Decile (1=Lowest, 10=Highest)', fontsize=12)\n",
                "ax.set_ylabel('Observed Uplift (percentage points)', fontsize=12)\n",
                "ax.set_title('Marginal Observed Uplift by Decile — Decile 9 Dip Analysis', fontsize=14, fontweight='bold')\n",
                "ax.set_xticks(decile_df['decile'])\n",
                "\n",
                "# Annotate Decile 9\n",
                "ax.annotate('Decile 9 DIP!\\n\"Sure Things\" mixed in', xy=(9, decile_df[decile_df['decile']==9]['observed_uplift'].values[0]*100),\n",
                "            xytext=(7, 1.0),\n",
                "            arrowprops=dict(arrowstyle='->', color='red', lw=2),\n",
                "            fontsize=11, color='red', fontweight='bold',\n",
                "            bbox=dict(boxstyle='round', facecolor='#ffcccc', alpha=0.8))\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/marginal_uplift_by_decile.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 7. Summary: Phase 3 Key Findings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"PHASE 3 SUMMARY: MODEL EVALUATION\")\n",
                "print(\"=\" * 70)\n",
                "print(f\"\"\"\n",
                "QINI CURVE RESULTS:\n",
                "  • Model AUUC: {auuc:.4f}\n",
                "  • Random AUUC: {auuc_random:.4f}\n",
                "  • AUUC Gain: {auuc_gain:.4f}\n",
                "  • Model is {(normalized_auuc-1)*100:.1f}% better than random targeting\n",
                "\n",
                "DECILE ANALYSIS (Key Findings):\n",
                "  • Best Decile: Decile 8 with +{decile_df[decile_df['decile']==8]['observed_uplift'].values[0]*100:.2f}pp observed lift\n",
                "  • Decile 10: +{decile_df[decile_df['decile']==10]['observed_uplift'].values[0]*100:.2f}pp observed lift\n",
                "  • Decile 9 ANOMALY: Only +{decile_df[decile_df['decile']==9]['observed_uplift'].values[0]*100:.2f}pp (model calibration issue)\n",
                "\n",
                "DECILE 9 ROOT CAUSE:\n",
                "  • Control rate: {decile_df[decile_df['decile']==9]['control_rate'].values[0]*100:.2f}% (highest of all deciles!)\n",
                "  • These are \"Sure Things\" — high baseline buyers\n",
                "  • Model confused high P(buy) with high persuadability\n",
                "  \n",
                "BUSINESS INSIGHT:\n",
                "  ✅ Model successfully identifies Persuadables (Deciles 8, 10 have highest lift)\n",
                "  ✅ Model beats random targeting by {(normalized_auuc-1)*100:.1f}%\n",
                "  ⚠️ Calibration issue: Decile 9 contains misclassified \"Sure Things\"\n",
                "  \n",
                "INTERVIEW TALKING POINT:\n",
                "  \"My model identified Persuadables, but I also discovered a calibration gap:\n",
                "  Decile 9 had high predicted uplift but low observed lift, because the model\n",
                "  confused 'likely to buy' with 'persuadable.' This is a known limitation of\n",
                "  T-Learners — they can struggle to separate base rates from treatment effects.\"\n",
                "\n",
                "→ Phase 4: Business simulation to calculate ROI impact\n",
                "\"\"\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}